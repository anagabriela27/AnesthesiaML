{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError, RootMeanSquaredError\n",
    "from keras.backend import clear_session\n",
    "from keras.callbacks import EarlyStopping\n",
    "from optuna.integration import TFKerasPruningCallback\n",
    "\n",
    "\n",
    "from google.cloud import storage\n",
    "from helpers import DataPreparator\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"mysql://root:Ana.mysql.18@127.0.0.1/vitaldb_anesthesiaml\")\n",
    "df = pd.read_sql('SELECT * FROM vitaldb_preprocessed', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clinical_info = pd.read_sql('SELECT * FROM vitaldb_clinical_info', con=engine)\n",
    "df_ci = pd.read_sql('SELECT * FROM vitaldb_clinical_info', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep = DataPreparator(df,df_clinical_info,time_window_before=10,static_features=['age','sex','asa'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_window_before=10\n",
    "static_features=['age','sex','asa']\n",
    "caseids_less = df['caseid'].unique()[:10]\n",
    "df_time_series = df.copy()\n",
    "target_col = 'insp_sevo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the data in the required format for LSTM\n",
    "X, y, caseids = data_prep.generate_sequences()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test, train_mask, test_mask, train_ids, test_ids = data_prep.split_train_test()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(trial):\n",
    "    # Clear the session to avoid memory issues\n",
    "    clear_session()\n",
    "\n",
    "    # Define the hyperparameters to be optimized\n",
    "    batchsize = trial.suggest_int(\"batchsize\", 64, 128, step=32)\n",
    "    lstm_units = trial.suggest_int(\"lstm_units\", 32, 64)\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.3)\n",
    "    learning_rate = trial.suggest_categorical(\"learning_rate\", [1e-4, 1e-3, 1e-2])\n",
    "    num_lstm_layers = trial.suggest_int('num_lstm_layers', 1, 2)\n",
    "\n",
    "    # Define the model architecture using the suggested hyperparameters\n",
    "    # LSTM layers with dropout\n",
    "    # The input shape is (timesteps, features), where timesteps is the length of the sequence and features is the number of features\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(lstm_units, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=(num_lstm_layers > 1)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    for _ in range(num_lstm_layers - 1):\n",
    "        model.add(LSTM(lstm_units, return_sequences=False))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(1))  # Output layer\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mse', metrics=['mae', RootMeanSquaredError(), 'mape'])\n",
    "\n",
    "    # Define callbacks for early stopping and pruning\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    pruning_callback = TFKerasPruningCallback(trial, monitor='val_loss')\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=30,\n",
    "        batch_size=batchsize,\n",
    "        callbacks=[early_stopping, pruning_callback],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Return the validation loss for optimization\n",
    "    val_loss = history.history['val_loss'][-1]\n",
    "    return val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,  mean_absolute_percentage_error, r2_score, accuracy_score\n",
    "\n",
    "# Calculate MAE\n",
    "mae_value = mean_absolute_error(y_test, y_pred)\n",
    "print(f\"Test MAE: {mae_value:.4f}\")\n",
    "\n",
    "# Calculate MAPE using sklearn\n",
    "mape_value = mean_absolute_percentage_error(y_test, y_pred)\n",
    "print(f\"Test MAPE (sklearn): {mape_value:.4f}\")\n",
    "\n",
    "# Calculate R-squared\n",
    "r2_value = r2_score(y_test, y_pred)\n",
    "print(f\"Test R-squared: {r2_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f\"Test MAPE (LSTM): {mape(y_test, y_pred):.1f}%\")\n",
    "print()\n",
    "\n",
    "# Plotting\n",
    "for caseid in test_ids[:5]:\n",
    "    case_mask = (caseids[test_mask] == caseid)\n",
    "    case_len = np.sum(case_mask)\n",
    "    if case_len == 0:\n",
    "        continue\n",
    "\n",
    "    print('CaseID {}, LSTM R^2={}'.format(caseid, \n",
    "      round(r2_score(y_test[case_mask], y_pred[case_mask]),3\n",
    "      )))\n",
    "\n",
    "    t = np.arange(0, case_len)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(t, y_test[case_mask], label='Real value of inspired sevo')  # Ground truth\n",
    "    plt.plot(t, y_pred[case_mask], label='Predicted value of inspired sevo')  # LSTM model\n",
    "    plt.legend()\n",
    "    plt.xlim([0, case_len])\n",
    "    #plt.ylim([0, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
